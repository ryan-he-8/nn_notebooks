{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86eb6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from layers import Embedding, FlattenConsecutive, Linear, BatchNorm1d, Tanh, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01596655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         ...,\n",
       "         [26, 26, 25],\n",
       "         [26, 25, 26],\n",
       "         [25, 26, 24]]),\n",
       " tensor([[ 5],\n",
       "         [13],\n",
       "         [13],\n",
       "         ...,\n",
       "         [26],\n",
       "         [24],\n",
       "         [ 0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset set up\n",
    "names = open(\"names.txt\", \"r\").read().splitlines()\n",
    "block_size = 3 # context window (in bigram block_size = 1)\n",
    "vocab = set([ch for name in names for ch in name])\n",
    "stoi = {ch: i+1 for i, ch in enumerate(sorted(list(vocab)))}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for name in names:\n",
    "    context = [0] * block_size\n",
    "    for ch in (name + '.'):\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append([ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ce894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = int(0.8 * len(names))\n",
    "n2 = int(0.9 * len(names))\n",
    "\n",
    "X_train, Y_train = X[:n1], Y[:n1]\n",
    "X_val, Y_val = X[n1:n2], Y[n1:n2]\n",
    "X_test, Y_test = X[n2:], Y[:n2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddc03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP w/out nn.Module\n",
    "\n",
    "emb_size = 10\n",
    "hidden_dim = 200\n",
    "\n",
    "ch2emb = torch.randn((vocab_size, emb_size)) # |V|, emb_size ; lookup table of embeddings for each character\n",
    "\n",
    "w1 = torch.randn((emb_size * block_size, hidden_dim)) * ((5/3)/(emb_size*block_size)**(1/2)) # kaiming initialization for tanh\n",
    "# b1 = torch.randn(hidden_dim) # will be \"removed\" in batch normalization\n",
    "\n",
    "gamma = torch.ones(hidden_dim)\n",
    "beta = torch.zeros(hidden_dim)\n",
    "\n",
    "running_mean = torch.zeros(hidden_dim)\n",
    "running_std = torch.zeros(hidden_dim)\n",
    "\n",
    "w2 = torch.randn((hidden_dim, vocab_size)) * 0.1 # reduce the size of the initial logits\n",
    "b2 = torch.randn(vocab_size) * 0.01\n",
    "\n",
    "parameters = [ch2emb, w1, w2, b2, gamma, beta]\n",
    "\n",
    "for param in parameters:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff7c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5509, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6068, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6941, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4474, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5186, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4612, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4477, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3842, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5232, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4934, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4962, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2568, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4449, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4183, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4034, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2556, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5068, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2842, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3933, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2615, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4447, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1910, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1398, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2812, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1738, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1488, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0606, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1381, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1892, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1404, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2141, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0634, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1628, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9972, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0614, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1528, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2844, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0777, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0527, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1141, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9037, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9862, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1467, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0599, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9785, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0717, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0885, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0782, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0273, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0704, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0301, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0364, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0695, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9957, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8774, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8880, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0364, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8991, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0746, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6672, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8808, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0205, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8382, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8828, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8819, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7641, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1146, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8440, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8768, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8819, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8861, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8856, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8875, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0407, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8498, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8797, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8393, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8586, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6765, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9008, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8243, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5806, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7814, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8780, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8166, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8632, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8730, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7635, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8154, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8067, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8629, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8123, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8916, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8085, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7883, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6906, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7455, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8459, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8968, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7439, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7379, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8096, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8129, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7818, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7841, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5931, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7936, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7929, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7743, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8941, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6475, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7787, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7167, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7530, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7476, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7912, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8536, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6765, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7681, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0107, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8663, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6693, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6847, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8193, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8049, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6829, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6460, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7785, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6150, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6959, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7863, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7738, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8163, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7425, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7811, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6170, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6874, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8238, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5585, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7840, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8116, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7925, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7657, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9831, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7889, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5949, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6522, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6661, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7430, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9011, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7381, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6991, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7677, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6703, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6663, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8131, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7302, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6811, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6266, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7342, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6058, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7056, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6877, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7418, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6837, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7641, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6357, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6289, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7836, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6047, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8063, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6413, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5116, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5876, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8246, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6155, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6374, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3911, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5849, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6496, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6211, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7102, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8031, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6764, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6935, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8011, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7435, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6521, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8912, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6403, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7472, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7383, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8220, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7472, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7248, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6468, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7598, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5762, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7871, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6254, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6966, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5466, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7554, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5368, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7499, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8434, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7997, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6984, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6007, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6770, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7740, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7096, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6055, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6862, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6877, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5327, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7760, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7061, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6186, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5733, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5134, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6307, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7727, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5643, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7482, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5895, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5740, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5347, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5511, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6378, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6250, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5255, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7418, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6159, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6292, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7621, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5776, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6308, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6071, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7316, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6266, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5975, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5683, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8170, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6537, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7416, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7186, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7677, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5864, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5848, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6315, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6182, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6617, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5831, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6858, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6613, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5499, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6621, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7190, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6530, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6086, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8682, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6284, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4856, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6057, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3926, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7063, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7863, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6455, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5180, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6305, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4815, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6534, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5397, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6153, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5657, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6745, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5419, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6515, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7465, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6319, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5710, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6182, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5834, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3961, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6050, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6904, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7145, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5573, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4607, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6643, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6734, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7264, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5825, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5898, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7871, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5878, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5659, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6005, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7580, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6257, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6039, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5024, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5269, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5579, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6365, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6934, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6389, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6984, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5029, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6418, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5727, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6589, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6368, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7128, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6304, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5136, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4739, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7264, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7045, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5174, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5641, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5964, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7253, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6091, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6713, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4805, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6080, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6142, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5360, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6171, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6309, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4893, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5362, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6330, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5731, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5210, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7795, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5964, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5313, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7484, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4832, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5917, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5527, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3441, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4814, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5932, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6249, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4893, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4698, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5676, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5938, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4780, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5701, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6145, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6719, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7063, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6237, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5972, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5730, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6144, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6441, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5939, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7268, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5437, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6093, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5965, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4755, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5521, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5250, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4446, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4127, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4966, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6601, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7101, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5527, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5508, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7310, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6682, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5400, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5897, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4316, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5008, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6049, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6409, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7357, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6652, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5733, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4139, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7051, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5460, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5249, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5146, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6359, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6599, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6197, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4563, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3984, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5128, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4759, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6825, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5368, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6088, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6283, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4863, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4741, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6586, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5777, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6038, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5492, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5476, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6275, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6015, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7711, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5912, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6257, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5190, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5443, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5208, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5008, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7742, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5330, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4980, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5054, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6447, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5608, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5320, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5163, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5313, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5717, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5475, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5633, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5918, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6266, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6896, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5189, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5315, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5935, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5983, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6549, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6807, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5857, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5417, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5228, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6752, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6113, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6107, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6180, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6187, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5193, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4778, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5714, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5714, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7536, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5792, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4118, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4376, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6470, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5331, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4994, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5703, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5507, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5819, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5963, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3651, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5829, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6155, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4636, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5128, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5651, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6119, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4502, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5092, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4912, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5219, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4830, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4917, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5378, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5812, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4811, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3953, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6246, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3839, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5524, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3987, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5838, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4607, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6022, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6760, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5034, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4434, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4836, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3352, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4965, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4883, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5390, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5186, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5703, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5568, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6198, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5163, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4423, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4661, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5674, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6193, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5508, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5313, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7248, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5830, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6604, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4364, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5873, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5936, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5009, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6339, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5898, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4744, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5639, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5779, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6994, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3365, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6920, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5832, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5104, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4560, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3275, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5726, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4034, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5246, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5249, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6679, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5188, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4259, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5289, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3683, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3993, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5695, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3918, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6363, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5026, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5005, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3631, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6729, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5206, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4977, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4540, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5479, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5792, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4649, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5617, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5746, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5604, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4788, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4290, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5729, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3812, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6261, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6471, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5295, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6502, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6941, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5040, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5618, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6482, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4703, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4901, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4496, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5609, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3513, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6040, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7058, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7399, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3783, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6829, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6392, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4601, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4781, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4578, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5214, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5785, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5069, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5067, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6294, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4752, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5112, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4482, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5323, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5469, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6603, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4457, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4557, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4827, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5108, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5805, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3343, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5622, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7427, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6478, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5634, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5480, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5739, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3779, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5083, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4658, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5591, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5410, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5261, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6855, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3646, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5747, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6343, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6065, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3992, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3639, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3962, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7760, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5783, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4588, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4015, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4155, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5378, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5451, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6265, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5294, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3645, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6055, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5712, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5930, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6754, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3623, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3543, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6239, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5636, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4595, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5252, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4176, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6013, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4101, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5132, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5158, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5883, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4739, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4174, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6151, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5147, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5667, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4103, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4687, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3839, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4277, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5526, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5100, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5315, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4965, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5873, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4439, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5086, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4215, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6110, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5948, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3910, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4977, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7412, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7278, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6111, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5029, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6206, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3927, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5355, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4795, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4848, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3749, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3642, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5501, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4076, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3486, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4181, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6405, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4998, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5852, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5923, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3474, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5041, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5526, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5167, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3462, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5973, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4262, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4743, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5195, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5293, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5100, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4337, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4162, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4828, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4650, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4142, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5081, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5026, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5033, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6457, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3947, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5885, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6234, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4407, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5589, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7581, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5846, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4074, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6690, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4510, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4631, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5686, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4092, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4626, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4923, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3585, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4281, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6402, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5229, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4329, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4808, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4525, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6072, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5773, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6016, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3957, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4238, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3523, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5493, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4135, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5537, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4664, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3979, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5925, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5247, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3666, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5969, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3747, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5246, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5013, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7144, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5011, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4062, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4195, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4632, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5601, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5144, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3427, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4522, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5622, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4092, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3994, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4592, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5611, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6544, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5576, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5002, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4131, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3491, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3758, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4503, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4499, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5072, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5184, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5177, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5170, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4050, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4166, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3707, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5399, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5804, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5700, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3743, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7200, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4823, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5732, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5584, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5573, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6897, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5624, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4594, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3727, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5407, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4103, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4938, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5318, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4979, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4926, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4509, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4858, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4851, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5146, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4541, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4730, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5284, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5382, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3750, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3267, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4235, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7030, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3538, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2900, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3810, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3139, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6408, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4816, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6415, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4910, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5738, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5968, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4444, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4238, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4307, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4032, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3161, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4250, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2713, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5958, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5211, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4730, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4107, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4849, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4651, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5345, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4626, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6405, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4140, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4479, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5322, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4901, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3962, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3445, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5043, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2946, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3955, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4701, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3172, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4651, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3421, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4926, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5306, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6065, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6580, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5773, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3815, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4968, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4650, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6290, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4683, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4989, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6069, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4260, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3513, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4705, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4547, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6140, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5212, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5083, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4876, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4694, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2908, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4755, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3935, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4460, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4963, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4022, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "epsilon = 1e-5\n",
    "momentum = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # mini batch creation and getting embeddings\n",
    "    batch_idx = torch.randint(0, X.shape[0], size=(batch_size,))\n",
    "    emb = ch2emb[X][batch_idx]                                 # len(dataset), block_size, emb_size\n",
    "    emb = emb.view((-1, emb_size * block_size))     # len(dataset), emb_size * block_size\n",
    "    ys = Y[batch_idx].view(-1)\n",
    "\n",
    "    # forward pass\n",
    "    hidden_emb1 = emb @ w1\n",
    "    # batch normalization\n",
    "    bn1_mean_i = hidden_emb1.mean(dim=0, keepdim=True)\n",
    "    bn1_std_i = (hidden_emb1.std(dim=0, keepdim=True)**2 + epsilon)**(1/2)\n",
    "    bn1 = gamma * (hidden_emb1 - bn1_mean_i)/bn1_std_i + beta\n",
    "\n",
    "    # for eval/generating examples\n",
    "    with torch.no_grad():\n",
    "        running_mean = (1-momentum) * running_mean + momentum * bn1_mean_i\n",
    "        running_std = (1-momentum) * running_std + momentum * bn1_std_i\n",
    "    \n",
    "    layer1 = bn1.tanh()               # len(dataset), d\n",
    "    logits = layer1 @ w2 + b2                        # len(dataset), vocab_size\n",
    "\n",
    "    # negative log likelihood (nll)\n",
    "\n",
    "    # counts = logits.exp()                            # len(dataset), vocab_size       \n",
    "    # probs = counts/counts.sum(dim=1, keepdim=True)   # len(dataset), vocab_size\n",
    "    # loss = -probs[torch.arange(emb.shape[0]), ys].log().mean()\n",
    "    # print(loss)\n",
    "    \n",
    "    # Y_one_hot = F.one_hot(ys, num_classes=vocab_size).view((-1, vocab_size))\n",
    "    # loss = -(Y_one_hot * probs).sum(dim=1).log().mean()\n",
    "    # print(loss)\n",
    "\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "    print(loss)\n",
    "\n",
    "    # backward pass\n",
    "    for param in parameters:\n",
    "        param.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update step\n",
    "    lr = 0.05\n",
    "    for param in parameters:\n",
    "        param.data += -lr * param.grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe59dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delliexx.\n",
      "jon.\n",
      "oy.\n"
     ]
    }
   ],
   "source": [
    "# generating samples\n",
    "\n",
    "num_names = 3\n",
    "\n",
    "for _ in range(num_names):\n",
    "\n",
    "    context = [0] * block_size\n",
    "    name = ''\n",
    "\n",
    "    while True:\n",
    "        # forward pass\n",
    "        emb = ch2emb[context]\n",
    "        emb = emb.view((1, -1))\n",
    "\n",
    "        # forward pass\n",
    "        hidden_emb1 = emb @ w1\n",
    "        # batch normalization\n",
    "        bn1 = gamma * (hidden_emb1 - running_mean)/(running_std**2 + epsilon)**(1/2) + beta\n",
    "        \n",
    "        layer1 = bn1.tanh()               # len(dataset), d\n",
    "        logits = layer1 @ w2 + b2                        # len(dataset), vocab_size\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "\n",
    "        name += itos[ix]\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e6d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP w/out nn.Module\n",
    "\n",
    "emb_size = 10\n",
    "hidden_dim = 300\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, emb_size),\n",
    "    FlattenConsecutive(block_size), Linear(emb_size * block_size, hidden_dim, bias=False), BatchNorm1d(hidden_dim), Tanh(),\n",
    "    Linear(hidden_dim, vocab_size),\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].W *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "\n",
    "for param in parameters:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56986b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2624, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2097, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1623, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0719, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0868, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0439, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0632, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9917, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8968, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0185, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8445, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8587, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8350, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7909, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7269, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0390, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9018, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8161, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8036, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7748, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7799, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7859, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7642, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8051, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8599, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7240, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7605, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7921, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7447, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7885, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7052, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8677, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7412, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7328, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7393, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8290, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6743, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5844, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7982, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6922, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7423, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7534, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7004, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7558, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6333, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6641, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7331, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5900, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6771, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5169, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6829, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5488, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6944, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7844, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7210, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5170, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6511, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6637, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4557, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6879, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7720, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6853, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6124, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6457, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7319, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6169, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6127, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5472, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5691, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8023, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6097, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5787, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5187, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6558, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4950, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5906, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5889, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4608, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5595, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5563, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5094, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5952, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6738, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4629, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7108, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5010, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3618, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6380, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6821, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7249, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6672, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4212, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6452, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5972, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6071, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6690, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6308, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6548, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5584, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4520, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5857, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5767, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5279, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5306, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6867, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5818, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5708, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6298, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5202, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7116, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6019, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5204, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5212, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5965, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5093, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5145, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5298, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4518, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5786, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6536, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5273, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4306, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4920, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5654, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3158, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6345, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5320, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6187, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4793, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4195, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6092, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3694, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5312, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4083, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5675, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6135, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4991, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5198, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4065, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4438, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4502, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5151, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5225, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4700, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5133, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5172, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4735, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5499, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5626, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3570, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4094, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4692, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4522, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5241, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5869, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4687, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4336, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5538, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4237, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6525, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4827, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4082, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3261, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3427, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2404, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5344, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5778, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4558, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4468, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5267, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3814, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4847, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3549, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6177, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5722, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5672, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6013, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3778, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4369, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5727, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3840, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4130, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5197, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4760, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5758, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3933, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6312, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4449, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4001, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4777, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4992, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3789, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6041, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5229, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3014, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6386, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4882, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4986, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5571, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4872, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5370, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3701, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4818, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5310, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4652, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5176, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6256, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4592, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4564, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4649, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4654, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3622, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3366, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5036, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4296, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5109, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4449, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4646, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4157, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5318, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3106, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5176, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5424, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3370, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4065, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4057, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4769, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4163, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6587, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1552, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3899, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5364, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3838, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2415, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5706, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3455, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4536, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4247, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4540, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5389, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3024, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4289, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4976, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4384, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3290, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5747, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6053, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4210, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4060, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3771, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3644, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2870, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3808, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3637, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3938, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3205, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4507, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3783, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4970, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2635, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4599, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3984, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4922, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3741, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3767, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3655, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3508, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5359, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4731, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2786, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3260, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4690, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4025, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2233, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4440, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3468, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2999, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2844, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2586, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5963, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4722, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5035, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5172, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4074, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3836, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4636, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4189, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1987, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2937, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2890, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2688, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3221, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4206, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3777, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2927, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2596, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2714, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1889, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3983, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3420, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3243, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3387, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4256, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4116, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3347, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4078, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5120, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4764, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4281, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2522, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4579, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3897, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3652, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4113, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3265, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5402, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4040, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3461, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4410, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3638, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5485, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2804, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6686, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2668, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1296, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3802, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2927, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4687, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2878, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3372, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2137, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2292, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4653, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4371, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2734, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2256, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3576, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4583, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2384, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4585, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4321, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2709, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4641, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3366, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2761, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4003, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3008, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4530, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4012, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3430, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3209, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4326, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4218, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3335, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3782, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4506, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3504, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4225, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4067, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1790, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1401, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3070, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3535, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3431, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3252, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2801, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2216, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4519, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3163, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3605, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1816, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1784, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3531, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3037, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3050, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2875, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4075, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2489, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1660, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4603, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3009, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4330, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3382, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2919, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4089, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3449, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3666, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3678, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2612, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1680, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3097, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2411, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3704, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2905, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2202, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3611, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4832, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5437, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2767, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3511, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1547, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3403, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3491, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1681, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0904, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4052, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2716, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3012, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2806, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0884, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3099, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3920, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1764, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0601, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3726, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1940, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3506, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3410, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2459, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5562, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2340, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5166, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2538, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2141, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2923, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3262, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3288, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4258, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3325, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4126, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3655, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2904, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3089, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0827, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2058, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3728, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1999, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3279, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3768, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4631, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3583, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3538, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2674, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3668, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2046, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3679, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3157, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4303, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1973, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3556, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2073, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3766, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2523, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3157, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4226, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3136, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2304, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2167, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3375, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2188, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3352, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3335, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3369, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2132, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3584, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2997, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1179, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2370, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2341, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1808, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2693, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1991, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3140, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2028, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4631, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2939, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1420, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3225, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2870, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3232, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3082, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0797, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3093, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3551, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4448, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1822, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1987, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4258, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3072, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4533, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3155, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1248, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1579, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5346, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2267, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3455, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1821, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1373, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3528, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3066, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2214, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3454, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1407, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1914, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3200, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3572, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2616, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2839, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4717, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3374, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2807, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2964, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1894, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3446, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6905, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1935, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3379, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2122, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4707, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1634, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3403, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2969, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2759, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1574, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2558, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2530, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2674, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3425, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2043, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2087, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3642, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3787, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2497, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2181, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2319, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1523, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1618, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1977, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2394, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1458, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2923, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1891, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0668, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4462, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2861, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2282, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2905, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2336, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2967, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3017, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2819, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4612, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2566, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3196, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2905, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2178, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3924, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3021, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1411, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2252, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2213, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2680, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4107, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2956, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1314, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1278, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3013, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2521, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1998, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3419, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3068, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1660, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3627, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3432, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2380, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1871, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3242, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3193, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1504, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3953, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4174, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2091, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1606, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0508, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3042, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2893, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3206, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1830, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1157, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3284, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5122, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1498, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2167, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0312, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1915, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2350, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3570, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3246, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3503, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0485, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3459, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3046, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3125, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1625, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3820, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1689, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3688, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2114, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4121, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3331, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3272, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1320, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3386, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2099, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0296, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2665, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2555, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1854, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1812, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4846, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2431, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0893, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3745, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3182, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2294, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1203, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3434, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2853, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2806, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3821, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1678, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2754, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0428, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2947, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1824, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1277, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2942, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2881, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2724, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2596, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3162, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3094, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2898, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3761, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2950, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1441, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3205, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0572, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3260, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2782, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2656, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1466, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3593, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1425, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1992, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3451, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3704, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3340, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2118, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2889, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1558, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2368, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1946, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1261, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1552, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2868, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2469, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0595, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0378, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0550, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1536, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2264, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2169, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3526, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2788, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2661, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2492, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0464, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3377, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2514, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2432, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3442, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1482, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2589, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1337, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3336, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2897, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9792, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1209, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1578, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3140, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1510, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2353, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2038, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1456, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2838, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2226, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2459, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1234, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3381, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1148, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2943, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2952, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2959, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2334, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2214, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0590, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1561, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2656, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0686, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2778, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1685, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2210, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2851, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2442, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0109, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3494, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2739, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2356, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1464, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0544, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3934, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0117, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1225, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2730, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1506, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2851, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2783, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1243, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1932, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2918, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2444, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2545, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0712, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2968, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3512, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2581, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0775, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2525, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2159, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0494, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3317, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2168, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2355, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2387, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1429, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3017, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0224, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0667, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1196, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9927, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0894, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2186, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0715, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2416, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1711, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2686, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1689, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2794, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3482, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2736, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1822, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2709, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3761, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1553, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3201, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2638, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1165, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1578, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2221, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2055, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3267, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1961, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1865, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1094, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2491, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2136, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1382, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2916, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2415, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2295, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3130, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3160, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1452, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1998, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1609, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1329, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1929, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1156, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2461, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2965, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0805, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4098, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2196, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4437, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2650, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1951, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1950, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1313, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1312, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3429, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0266, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1027, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1933, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1258, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2147, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1874, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1227, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3575, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2573, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1812, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3372, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2341, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1757, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2936, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # mini batch creation and getting embeddings\n",
    "    batch_idx = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    xs = X_train[batch_idx]\n",
    "    ys = Y[batch_idx].view(-1)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(xs)\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "\n",
    "    # backward pass\n",
    "    for param in parameters:\n",
    "        param.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update step\n",
    "    lr = 0.05\n",
    "    for param in parameters:\n",
    "        param.data += -lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55724556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f32a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamaniya.\n",
      "aylyne.\n",
      "amgeqy.\n"
     ]
    }
   ],
   "source": [
    "# generating samples\n",
    "\n",
    "num_names = 3\n",
    "\n",
    "for _ in range(num_names):\n",
    "    context = [0] * block_size\n",
    "    name = ''\n",
    "\n",
    "    while True:\n",
    "        # forward pass\n",
    "        logits = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "\n",
    "        name += itos[ix]\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8529c",
   "metadata": {},
   "source": [
    "# Wavenet Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf18666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "         [ 0,  0,  0,  ...,  0,  0,  5],\n",
       "         [ 0,  0,  0,  ...,  0,  5, 13],\n",
       "         ...,\n",
       "         [ 0,  0,  0,  ..., 26, 26, 25],\n",
       "         [ 0,  0,  0,  ..., 26, 25, 26],\n",
       "         [ 0,  0,  0,  ..., 25, 26, 24]]),\n",
       " tensor([ 5, 13, 13,  ..., 26, 24,  0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset set up\n",
    "names = open(\"names.txt\", \"r\").read().splitlines()\n",
    "block_size = 8 # context window (in bigram block_size = 1)\n",
    "vocab = set([ch for name in names for ch in name])\n",
    "stoi = {ch: i+1 for i, ch in enumerate(sorted(list(vocab)))}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for name in names:\n",
    "    context = [0] * block_size\n",
    "    for ch in (name + '.'):\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "n1 = int(0.8 * len(names))\n",
    "n2 = int(0.9 * len(names))\n",
    "\n",
    "X_train, Y_train = X[:n1], Y[:n1]\n",
    "X_val, Y_val = X[n1:n2], Y[n1:n2]\n",
    "X_test, Y_test = X[n2:], Y[:n2]\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51282116",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 24\n",
    "hidden_dim = 200\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, emb_size),\n",
    "    FlattenConsecutive(2), Linear(2 * emb_size, hidden_dim, bias=False), BatchNorm1d(hidden_dim), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(2 * hidden_dim, hidden_dim, bias=False), BatchNorm1d(hidden_dim), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(2 * hidden_dim, hidden_dim, bias=False), BatchNorm1d(hidden_dim), Tanh(),\n",
    "    Linear(hidden_dim, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].W *= 0.1\n",
    "\n",
    "parameters= model.parameters()\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "371560a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2894446849823\n",
      "3.292128562927246\n",
      "3.248857259750366\n",
      "3.2474045753479004\n",
      "3.230952501296997\n",
      "3.201843500137329\n",
      "3.20062255859375\n",
      "3.1586461067199707\n",
      "3.1550023555755615\n",
      "3.1177287101745605\n",
      "3.1279847621917725\n",
      "3.050001621246338\n",
      "3.0574021339416504\n",
      "3.0316905975341797\n",
      "3.0652782917022705\n",
      "3.0694491863250732\n",
      "2.9013493061065674\n",
      "2.968414306640625\n",
      "2.960031509399414\n",
      "2.9912269115448\n",
      "2.982114791870117\n",
      "3.05415415763855\n",
      "2.820807933807373\n",
      "2.8316924571990967\n",
      "2.743335485458374\n",
      "2.88623046875\n",
      "2.97670316696167\n",
      "2.873579263687134\n",
      "2.9468770027160645\n",
      "2.9458916187286377\n",
      "2.8086752891540527\n",
      "2.8504011631011963\n",
      "2.8736510276794434\n",
      "2.838120460510254\n",
      "2.850911855697632\n",
      "2.832043409347534\n",
      "2.8063714504241943\n",
      "2.843447208404541\n",
      "2.8314740657806396\n",
      "2.781594753265381\n",
      "2.840872287750244\n",
      "2.802152633666992\n",
      "2.90743350982666\n",
      "2.717411756515503\n",
      "2.7977685928344727\n",
      "2.7603647708892822\n",
      "2.9353370666503906\n",
      "2.747422218322754\n",
      "2.740048408508301\n",
      "2.8093421459198\n",
      "2.699428081512451\n",
      "2.6177637577056885\n",
      "2.761293411254883\n",
      "2.851919174194336\n",
      "2.6821205615997314\n",
      "2.6594603061676025\n",
      "2.635054349899292\n",
      "2.738874673843384\n",
      "2.7484421730041504\n",
      "2.7137153148651123\n",
      "2.6048903465270996\n",
      "2.7468693256378174\n",
      "2.694410800933838\n",
      "2.8141987323760986\n",
      "2.711862325668335\n",
      "2.698404550552368\n",
      "2.569894790649414\n",
      "2.578693389892578\n",
      "2.691192626953125\n",
      "2.6421101093292236\n",
      "2.828678607940674\n",
      "2.600736379623413\n",
      "2.744180202484131\n",
      "2.501253843307495\n",
      "2.6715142726898193\n",
      "2.79266095161438\n",
      "2.7320332527160645\n",
      "2.5579569339752197\n",
      "2.5858705043792725\n",
      "2.529209852218628\n",
      "2.4575998783111572\n",
      "2.7051055431365967\n",
      "2.5830929279327393\n",
      "2.5594229698181152\n",
      "2.735438346862793\n",
      "2.68632173538208\n",
      "2.538757085800171\n",
      "2.532292127609253\n",
      "2.692664384841919\n",
      "2.5214931964874268\n",
      "2.6529691219329834\n",
      "2.533745050430298\n",
      "2.50346040725708\n",
      "2.816129446029663\n",
      "2.351595640182495\n",
      "2.445251226425171\n",
      "2.47721004486084\n",
      "2.6391515731811523\n",
      "2.5949199199676514\n",
      "2.5500361919403076\n",
      "2.668639898300171\n",
      "2.633881092071533\n",
      "2.609619140625\n",
      "2.53330135345459\n",
      "2.641141176223755\n",
      "2.4892680644989014\n",
      "2.579131603240967\n",
      "2.566474199295044\n",
      "2.4084789752960205\n",
      "2.670682907104492\n",
      "2.455307722091675\n",
      "2.4425971508026123\n",
      "2.581382989883423\n",
      "2.6002120971679688\n",
      "2.45986008644104\n",
      "2.5933399200439453\n",
      "2.6472723484039307\n",
      "2.5348198413848877\n",
      "2.5015950202941895\n",
      "2.471283197402954\n",
      "2.358243465423584\n",
      "2.5771048069000244\n",
      "2.460392475128174\n",
      "2.3734207153320312\n",
      "2.491244316101074\n",
      "2.313724994659424\n",
      "2.4148011207580566\n",
      "2.4606573581695557\n",
      "2.6371357440948486\n",
      "2.404749870300293\n",
      "2.539719343185425\n",
      "2.3459906578063965\n",
      "2.548537492752075\n",
      "2.2889459133148193\n",
      "2.3270559310913086\n",
      "2.5652594566345215\n",
      "2.378483772277832\n",
      "2.299661636352539\n",
      "2.605581521987915\n",
      "2.680943250656128\n",
      "2.577326536178589\n",
      "2.375678062438965\n",
      "2.4130635261535645\n",
      "2.35127854347229\n",
      "2.3872385025024414\n",
      "2.4917235374450684\n",
      "2.437649965286255\n",
      "2.655005931854248\n",
      "2.4898862838745117\n",
      "2.7195944786071777\n",
      "2.388373613357544\n",
      "2.5060110092163086\n",
      "2.440870523452759\n",
      "2.614983320236206\n",
      "2.447338104248047\n",
      "2.525498628616333\n",
      "2.3807997703552246\n",
      "2.4514260292053223\n",
      "2.565089702606201\n",
      "2.50016450881958\n",
      "2.268550395965576\n",
      "2.3855957984924316\n",
      "2.4429407119750977\n",
      "2.3269481658935547\n",
      "2.37141752243042\n",
      "2.594635009765625\n",
      "2.4067001342773438\n",
      "2.2418129444122314\n",
      "2.5371692180633545\n",
      "2.37231183052063\n",
      "2.3367984294891357\n",
      "2.2619829177856445\n",
      "2.4032866954803467\n",
      "2.3121323585510254\n",
      "2.438530921936035\n",
      "2.340747356414795\n",
      "2.5519766807556152\n",
      "2.2395243644714355\n",
      "2.3373799324035645\n",
      "2.1459743976593018\n",
      "2.3466267585754395\n",
      "2.3404273986816406\n",
      "2.391385316848755\n",
      "2.384127616882324\n",
      "2.2341487407684326\n",
      "2.3092947006225586\n",
      "2.3087615966796875\n",
      "2.474745988845825\n",
      "2.342266321182251\n",
      "2.266068458557129\n",
      "2.207162618637085\n",
      "2.3044233322143555\n",
      "2.2836461067199707\n",
      "2.1434433460235596\n",
      "2.2634239196777344\n",
      "2.499959707260132\n",
      "2.2078020572662354\n",
      "2.282531261444092\n",
      "2.3455326557159424\n",
      "2.5079610347747803\n",
      "2.288461685180664\n",
      "2.5163795948028564\n",
      "2.3556151390075684\n",
      "2.3476977348327637\n",
      "2.3499410152435303\n",
      "2.1938657760620117\n",
      "2.3203184604644775\n",
      "2.3269243240356445\n",
      "2.371703624725342\n",
      "2.3756206035614014\n",
      "2.1379358768463135\n",
      "2.2868402004241943\n",
      "2.430737018585205\n",
      "2.2171595096588135\n",
      "2.086765766143799\n",
      "2.348498821258545\n",
      "2.2172906398773193\n",
      "2.2317283153533936\n",
      "2.2369306087493896\n",
      "2.4112157821655273\n",
      "2.35227108001709\n",
      "2.2723512649536133\n",
      "2.2231979370117188\n",
      "2.10184645652771\n",
      "2.321645975112915\n",
      "2.257965087890625\n",
      "2.2486636638641357\n",
      "2.2166969776153564\n",
      "2.3796799182891846\n",
      "2.3321120738983154\n",
      "2.410980224609375\n",
      "2.5200541019439697\n",
      "2.4026451110839844\n",
      "2.323695659637451\n",
      "2.1421279907226562\n",
      "2.3961164951324463\n",
      "2.2481465339660645\n",
      "2.2837626934051514\n",
      "2.1687793731689453\n",
      "2.118314027786255\n",
      "2.1441495418548584\n",
      "2.1291966438293457\n",
      "2.457940101623535\n",
      "2.3417890071868896\n",
      "2.1680150032043457\n",
      "2.3487401008605957\n",
      "2.3300535678863525\n",
      "2.399364471435547\n",
      "2.198951244354248\n",
      "2.2824466228485107\n",
      "2.1397387981414795\n",
      "2.310899019241333\n",
      "2.3632009029388428\n",
      "2.0234954357147217\n",
      "2.4159486293792725\n",
      "2.2228524684906006\n",
      "2.2297306060791016\n",
      "2.230825424194336\n",
      "2.2699568271636963\n",
      "2.362372875213623\n",
      "2.3169193267822266\n",
      "2.4333810806274414\n",
      "2.3454010486602783\n",
      "2.2804319858551025\n",
      "2.346867799758911\n",
      "2.1906449794769287\n",
      "2.2543747425079346\n",
      "2.178487777709961\n",
      "2.1946682929992676\n",
      "2.3266994953155518\n",
      "2.322509527206421\n",
      "2.1529765129089355\n",
      "2.1652445793151855\n",
      "2.2874679565429688\n",
      "2.1219632625579834\n",
      "2.4073104858398438\n",
      "2.355013132095337\n",
      "2.2560384273529053\n",
      "2.212961435317993\n",
      "2.1657016277313232\n",
      "2.4070475101470947\n",
      "2.312324047088623\n",
      "2.0161023139953613\n",
      "2.1852760314941406\n",
      "2.213031768798828\n",
      "2.1177570819854736\n",
      "2.2939655780792236\n",
      "2.084256410598755\n",
      "2.148045539855957\n",
      "2.240304708480835\n",
      "2.4867517948150635\n",
      "2.142069101333618\n",
      "2.2423555850982666\n",
      "2.1344528198242188\n",
      "2.0371816158294678\n",
      "2.2809903621673584\n",
      "2.3881328105926514\n",
      "2.3508718013763428\n",
      "2.2259514331817627\n",
      "2.205552101135254\n",
      "2.3046717643737793\n",
      "2.045861005783081\n",
      "2.203254461288452\n",
      "2.0489821434020996\n",
      "2.131260395050049\n",
      "2.1698970794677734\n",
      "2.175339937210083\n",
      "2.083540201187134\n",
      "2.0941483974456787\n",
      "2.201007604598999\n",
      "2.3119306564331055\n",
      "1.9985814094543457\n",
      "1.946845293045044\n",
      "2.2061562538146973\n",
      "2.2240636348724365\n",
      "2.152050733566284\n",
      "1.9498907327651978\n",
      "2.165027379989624\n",
      "2.2524962425231934\n",
      "2.131664276123047\n",
      "2.0259792804718018\n",
      "2.236611843109131\n",
      "2.022664785385132\n",
      "2.0979928970336914\n",
      "2.2396292686462402\n",
      "2.1178691387176514\n",
      "2.0990493297576904\n",
      "2.0877883434295654\n",
      "2.1622369289398193\n",
      "2.17431640625\n",
      "2.207566738128662\n",
      "2.1983511447906494\n",
      "2.2749805450439453\n",
      "2.2376317977905273\n",
      "2.1637625694274902\n",
      "2.309368133544922\n",
      "2.1995322704315186\n",
      "2.1770730018615723\n",
      "2.1411612033843994\n",
      "2.1781537532806396\n",
      "2.1114182472229004\n",
      "2.300562858581543\n",
      "2.0076863765716553\n",
      "2.0939605236053467\n",
      "2.1108644008636475\n",
      "2.139427423477173\n",
      "2.0979788303375244\n",
      "2.3056859970092773\n",
      "2.1961541175842285\n",
      "2.232924461364746\n",
      "2.116164445877075\n",
      "2.137017011642456\n",
      "2.055452823638916\n",
      "2.317047357559204\n",
      "2.143604278564453\n",
      "2.1095240116119385\n",
      "2.1999499797821045\n",
      "2.116062641143799\n",
      "2.193467140197754\n",
      "2.2218949794769287\n",
      "2.0783586502075195\n",
      "2.2711496353149414\n",
      "2.0540859699249268\n",
      "2.1010780334472656\n",
      "1.9584391117095947\n",
      "2.0925917625427246\n",
      "2.070263624191284\n",
      "2.0540757179260254\n",
      "2.0441293716430664\n",
      "2.1790313720703125\n",
      "2.252127170562744\n",
      "2.166508436203003\n",
      "1.9877101182937622\n",
      "2.0884933471679688\n",
      "1.9283639192581177\n",
      "2.220426559448242\n",
      "1.9401271343231201\n",
      "2.3318049907684326\n",
      "2.0841729640960693\n",
      "2.144434928894043\n",
      "2.0570855140686035\n",
      "2.2936365604400635\n",
      "1.961008071899414\n",
      "1.9554908275604248\n",
      "2.205202341079712\n",
      "1.9406895637512207\n",
      "2.09097957611084\n",
      "2.1436564922332764\n",
      "1.9294471740722656\n",
      "2.225019693374634\n",
      "2.0486252307891846\n",
      "2.384944200515747\n",
      "2.0030386447906494\n",
      "2.1293210983276367\n",
      "2.242748975753784\n",
      "2.3277108669281006\n",
      "1.9646128416061401\n",
      "1.890759825706482\n",
      "2.2564480304718018\n",
      "2.102475643157959\n",
      "2.0555002689361572\n",
      "2.040034055709839\n",
      "2.0828354358673096\n",
      "2.0684211254119873\n",
      "1.9515049457550049\n",
      "2.0767369270324707\n",
      "2.344491481781006\n",
      "2.192370891571045\n",
      "2.0905025005340576\n",
      "2.2317111492156982\n",
      "2.1368722915649414\n",
      "2.1443333625793457\n",
      "2.044898271560669\n",
      "2.1060755252838135\n",
      "2.038940191268921\n",
      "2.1388797760009766\n",
      "1.964338779449463\n",
      "2.3383865356445312\n",
      "1.9887902736663818\n",
      "2.067131757736206\n",
      "2.085465431213379\n",
      "2.1029551029205322\n",
      "1.9979716539382935\n",
      "2.1929333209991455\n",
      "1.9658869504928589\n",
      "2.0396311283111572\n",
      "2.0825304985046387\n",
      "2.103989601135254\n",
      "2.313964605331421\n",
      "1.9143868684768677\n",
      "2.078883171081543\n",
      "1.972341775894165\n",
      "2.1625046730041504\n",
      "1.8688768148422241\n",
      "2.079073190689087\n",
      "2.042241096496582\n",
      "2.036710739135742\n",
      "2.191107988357544\n",
      "2.0486857891082764\n",
      "2.0103554725646973\n",
      "2.1937291622161865\n",
      "2.223151683807373\n",
      "2.1691644191741943\n",
      "2.17805552482605\n",
      "2.0551772117614746\n",
      "2.0762484073638916\n",
      "2.00496768951416\n",
      "2.0739293098449707\n",
      "2.2909493446350098\n",
      "2.135098695755005\n",
      "2.2020177841186523\n",
      "1.9723261594772339\n",
      "2.0585172176361084\n",
      "2.0950069427490234\n",
      "1.9674872159957886\n",
      "2.1086506843566895\n",
      "2.0098984241485596\n",
      "2.1218206882476807\n",
      "2.0162718296051025\n",
      "2.078012228012085\n",
      "2.1136398315429688\n",
      "2.0967700481414795\n",
      "2.0503833293914795\n",
      "2.1161301136016846\n",
      "2.0994365215301514\n",
      "2.0501515865325928\n",
      "2.0309605598449707\n",
      "2.085975408554077\n",
      "2.1187939643859863\n",
      "2.0122671127319336\n",
      "2.0625884532928467\n",
      "2.1756694316864014\n",
      "2.0282392501831055\n",
      "2.0198776721954346\n",
      "2.146348714828491\n",
      "1.8983078002929688\n",
      "1.9023897647857666\n",
      "1.9859684705734253\n",
      "2.0692481994628906\n",
      "1.8814245462417603\n",
      "1.9730591773986816\n",
      "2.0281946659088135\n",
      "2.0136632919311523\n",
      "1.9366132020950317\n",
      "2.2552990913391113\n",
      "1.869112491607666\n",
      "1.8164334297180176\n",
      "2.1271164417266846\n",
      "1.8985239267349243\n",
      "2.0686542987823486\n",
      "2.1121420860290527\n",
      "2.2260046005249023\n",
      "2.045257806777954\n",
      "1.9924800395965576\n",
      "1.909533143043518\n",
      "2.059663772583008\n",
      "1.9744410514831543\n",
      "1.9820266962051392\n",
      "2.1107094287872314\n",
      "2.198596954345703\n",
      "1.9980345964431763\n",
      "2.1268210411071777\n",
      "2.107694149017334\n",
      "1.8330224752426147\n",
      "1.9771934747695923\n",
      "1.864202618598938\n",
      "1.8866521120071411\n",
      "2.160126209259033\n",
      "2.0320396423339844\n",
      "2.112290382385254\n",
      "2.197791576385498\n",
      "2.1603169441223145\n",
      "2.088411569595337\n",
      "2.0642428398132324\n",
      "1.9856804609298706\n",
      "2.0813345909118652\n",
      "2.140822172164917\n",
      "1.945630431175232\n",
      "1.8441581726074219\n",
      "1.987321138381958\n",
      "2.148212194442749\n",
      "2.0371575355529785\n",
      "2.2043275833129883\n",
      "2.2938075065612793\n",
      "2.053748846054077\n",
      "2.0186901092529297\n",
      "2.019601345062256\n",
      "1.995173692703247\n",
      "2.173666477203369\n",
      "1.963996410369873\n",
      "2.003321647644043\n",
      "1.967421054840088\n",
      "2.0724709033966064\n",
      "1.9743760824203491\n",
      "1.958303689956665\n",
      "1.9153927564620972\n",
      "2.054985284805298\n",
      "2.20143985748291\n",
      "2.0056209564208984\n",
      "2.0212440490722656\n",
      "2.169900894165039\n",
      "2.0592854022979736\n",
      "2.120281219482422\n",
      "2.0343058109283447\n",
      "1.9862444400787354\n",
      "2.023219108581543\n",
      "2.27873158454895\n",
      "1.981284260749817\n",
      "2.0129330158233643\n",
      "2.091104745864868\n",
      "1.913753628730774\n",
      "2.050778388977051\n",
      "1.856347680091858\n",
      "2.0341508388519287\n",
      "2.0515389442443848\n",
      "2.080443859100342\n",
      "1.8192427158355713\n",
      "1.9458516836166382\n",
      "2.0504331588745117\n",
      "1.8931992053985596\n",
      "2.211564302444458\n",
      "1.971509337425232\n",
      "1.9656260013580322\n",
      "1.9829721450805664\n",
      "1.9660862684249878\n",
      "2.0786094665527344\n",
      "2.0039823055267334\n",
      "1.9716113805770874\n",
      "2.044297695159912\n",
      "2.006849527359009\n",
      "1.9976497888565063\n",
      "1.9777796268463135\n",
      "1.8561195135116577\n",
      "1.977265477180481\n",
      "2.119852066040039\n",
      "1.9980897903442383\n",
      "1.9067975282669067\n",
      "2.1324031352996826\n",
      "1.900688648223877\n",
      "1.8307334184646606\n",
      "2.0161361694335938\n",
      "2.0246381759643555\n",
      "1.9461954832077026\n",
      "2.0528814792633057\n",
      "1.9181244373321533\n",
      "1.894783854484558\n",
      "1.9668254852294922\n",
      "1.995374083518982\n",
      "2.01033091545105\n",
      "1.7766484022140503\n",
      "2.0688717365264893\n",
      "1.7952858209609985\n",
      "2.0366857051849365\n",
      "1.9383351802825928\n",
      "1.9268391132354736\n",
      "2.170100450515747\n",
      "2.051840305328369\n",
      "1.887601613998413\n",
      "2.0789153575897217\n",
      "1.8083117008209229\n",
      "2.028512716293335\n",
      "2.23720121383667\n",
      "2.09999942779541\n",
      "2.1159446239471436\n",
      "1.985190987586975\n",
      "1.9861631393432617\n",
      "1.9212404489517212\n",
      "1.971629023551941\n",
      "2.2181742191314697\n",
      "1.9440324306488037\n",
      "1.9238593578338623\n",
      "2.0115389823913574\n",
      "2.1096079349517822\n",
      "2.0913264751434326\n",
      "1.9110947847366333\n",
      "2.2066049575805664\n",
      "1.9502694606781006\n",
      "2.0406839847564697\n",
      "1.9994654655456543\n",
      "1.9782036542892456\n",
      "1.993969440460205\n",
      "1.8942854404449463\n",
      "1.9847766160964966\n",
      "1.8744350671768188\n",
      "2.1883108615875244\n",
      "2.137150526046753\n",
      "1.9930415153503418\n",
      "1.9182707071304321\n",
      "2.0728471279144287\n",
      "2.1696252822875977\n",
      "2.020448684692383\n",
      "2.1480910778045654\n",
      "1.9675319194793701\n",
      "2.067103385925293\n",
      "2.0710322856903076\n",
      "2.1021807193756104\n",
      "2.098259925842285\n",
      "1.965142011642456\n",
      "1.7923152446746826\n",
      "2.0388801097869873\n",
      "2.0726497173309326\n",
      "2.079263687133789\n",
      "2.0083937644958496\n",
      "1.8803306818008423\n",
      "2.0067601203918457\n",
      "2.0591049194335938\n",
      "2.027913808822632\n",
      "1.9729148149490356\n",
      "1.9495927095413208\n",
      "2.0344746112823486\n",
      "1.9637974500656128\n",
      "1.8540841341018677\n",
      "1.709616780281067\n",
      "1.9338676929473877\n",
      "1.8256747722625732\n",
      "1.9646358489990234\n",
      "2.165900945663452\n",
      "1.7819745540618896\n",
      "1.7610042095184326\n",
      "1.838409185409546\n",
      "2.061833143234253\n",
      "1.9191471338272095\n",
      "1.9085880517959595\n",
      "1.9014859199523926\n",
      "1.9773542881011963\n",
      "1.7836366891860962\n",
      "1.8302239179611206\n",
      "2.063835620880127\n",
      "2.059788227081299\n",
      "2.0834295749664307\n",
      "1.9981739521026611\n",
      "2.0430688858032227\n",
      "1.9067773818969727\n",
      "1.8016031980514526\n",
      "2.0016753673553467\n",
      "2.0817246437072754\n",
      "1.8824769258499146\n",
      "2.0296542644500732\n",
      "2.081228733062744\n",
      "1.8517383337020874\n",
      "1.9838416576385498\n",
      "1.898080825805664\n",
      "1.8526959419250488\n",
      "1.9972202777862549\n",
      "2.025101661682129\n",
      "2.096843957901001\n",
      "1.9921015501022339\n",
      "2.0805227756500244\n",
      "1.9087470769882202\n",
      "1.912153959274292\n",
      "1.9163457155227661\n",
      "1.975986123085022\n",
      "1.8402495384216309\n",
      "1.8566346168518066\n",
      "2.0832347869873047\n",
      "1.935765266418457\n",
      "1.7869610786437988\n",
      "1.8079875707626343\n",
      "1.85475754737854\n",
      "1.9260004758834839\n",
      "1.910270094871521\n",
      "1.9282358884811401\n",
      "2.08906626701355\n",
      "1.8950543403625488\n",
      "1.828418493270874\n",
      "1.9535406827926636\n",
      "1.8209439516067505\n",
      "1.8145782947540283\n",
      "1.8665218353271484\n",
      "1.9018069505691528\n",
      "1.820422887802124\n",
      "1.9165910482406616\n",
      "1.8762335777282715\n",
      "1.8668166399002075\n",
      "1.9695415496826172\n",
      "1.9685574769973755\n",
      "2.0950124263763428\n",
      "2.04118275642395\n",
      "1.8630404472351074\n",
      "2.040069341659546\n",
      "1.91924250125885\n",
      "1.9276002645492554\n",
      "1.8640737533569336\n",
      "2.0648443698883057\n",
      "2.0384931564331055\n",
      "1.6935992240905762\n",
      "1.8966141939163208\n",
      "1.864022970199585\n",
      "1.8829838037490845\n",
      "1.8894658088684082\n",
      "1.7673723697662354\n",
      "1.852421760559082\n",
      "2.210590362548828\n",
      "2.0637004375457764\n",
      "2.227198839187622\n",
      "2.1031341552734375\n",
      "2.0360960960388184\n",
      "1.9103738069534302\n",
      "2.0336055755615234\n",
      "1.9678248167037964\n",
      "1.9055989980697632\n",
      "1.9440326690673828\n",
      "2.0744190216064453\n",
      "1.9505747556686401\n",
      "1.9512138366699219\n",
      "1.7732787132263184\n",
      "1.9425750970840454\n",
      "2.111050605773926\n",
      "1.959591269493103\n",
      "1.9246388673782349\n",
      "2.0808446407318115\n",
      "1.954511284828186\n",
      "2.0426909923553467\n",
      "2.023972272872925\n",
      "2.0736377239227295\n",
      "2.1129567623138428\n",
      "1.9278093576431274\n",
      "1.8543599843978882\n",
      "1.7795904874801636\n",
      "1.892296552658081\n",
      "1.7128522396087646\n",
      "1.8436983823776245\n",
      "2.0200490951538086\n",
      "2.0797626972198486\n",
      "1.9651453495025635\n",
      "1.807246208190918\n",
      "2.1320858001708984\n",
      "1.9669675827026367\n",
      "2.1529524326324463\n",
      "1.9944865703582764\n",
      "2.0160019397735596\n",
      "2.0045955181121826\n",
      "1.9910433292388916\n",
      "1.7305071353912354\n",
      "1.894806146621704\n",
      "1.983486533164978\n",
      "1.9147189855575562\n",
      "1.9735804796218872\n",
      "2.005110263824463\n",
      "1.8763927221298218\n",
      "1.9780781269073486\n",
      "1.9225566387176514\n",
      "1.9392932653427124\n",
      "2.023399591445923\n",
      "1.8047029972076416\n",
      "1.8170512914657593\n",
      "2.00156569480896\n",
      "1.9583786725997925\n",
      "1.952657699584961\n",
      "2.134758472442627\n",
      "1.9964158535003662\n",
      "1.9354276657104492\n",
      "1.717491626739502\n",
      "1.949663758277893\n",
      "2.0110795497894287\n",
      "1.7981308698654175\n",
      "1.8153302669525146\n",
      "1.8628273010253906\n",
      "1.996117353439331\n",
      "1.9966377019882202\n",
      "1.8304420709609985\n",
      "1.8379868268966675\n",
      "1.772088885307312\n",
      "1.7718212604522705\n",
      "1.9471702575683594\n",
      "1.9007374048233032\n",
      "1.826904296875\n",
      "2.0425596237182617\n",
      "1.9096611738204956\n",
      "2.076354742050171\n",
      "1.820678472518921\n",
      "1.677055835723877\n",
      "1.8487569093704224\n",
      "2.1621575355529785\n",
      "1.8906302452087402\n",
      "2.0285158157348633\n",
      "1.9092713594436646\n",
      "1.889936923980713\n",
      "1.7715657949447632\n",
      "2.067382335662842\n",
      "2.0252349376678467\n",
      "1.6730453968048096\n",
      "1.9445114135742188\n",
      "1.7323051691055298\n",
      "1.9382473230361938\n",
      "1.8271323442459106\n",
      "1.783267855644226\n",
      "2.009091377258301\n",
      "1.8851631879806519\n",
      "1.9568864107131958\n",
      "1.7026485204696655\n",
      "1.9707744121551514\n",
      "1.915765643119812\n",
      "1.975019931793213\n",
      "1.9555096626281738\n",
      "1.9462685585021973\n",
      "2.102891683578491\n",
      "2.028573989868164\n",
      "1.9413197040557861\n",
      "1.99234938621521\n",
      "1.8704510927200317\n",
      "1.8498040437698364\n",
      "2.050962209701538\n",
      "1.8192110061645508\n",
      "2.000509738922119\n",
      "2.0892868041992188\n",
      "2.0000336170196533\n",
      "1.957836627960205\n",
      "1.8100554943084717\n",
      "1.9641175270080566\n",
      "1.970211386680603\n",
      "2.1172046661376953\n",
      "1.9755162000656128\n",
      "1.96294367313385\n",
      "1.703665018081665\n",
      "1.7696908712387085\n",
      "1.9020341634750366\n",
      "1.846738576889038\n",
      "1.8700941801071167\n",
      "1.7768700122833252\n",
      "1.820710301399231\n",
      "2.255980968475342\n",
      "1.8801764249801636\n",
      "1.8014415502548218\n",
      "2.0935938358306885\n",
      "2.141749143600464\n",
      "2.1356163024902344\n",
      "1.85157310962677\n",
      "1.8953419923782349\n",
      "1.9120051860809326\n",
      "1.883450984954834\n",
      "1.913643479347229\n",
      "1.885185718536377\n",
      "1.9090014696121216\n",
      "1.9609594345092773\n",
      "1.658349871635437\n",
      "1.9763246774673462\n",
      "1.842033863067627\n",
      "2.0594704151153564\n",
      "1.9193477630615234\n",
      "1.9669674634933472\n",
      "1.7892402410507202\n",
      "1.8471882343292236\n",
      "1.7485712766647339\n",
      "2.0522098541259766\n",
      "2.0410258769989014\n",
      "2.0985891819000244\n",
      "1.792389988899231\n",
      "1.8432867527008057\n",
      "1.8030272722244263\n",
      "1.9972325563430786\n",
      "1.8603596687316895\n",
      "1.7652473449707031\n",
      "1.8144476413726807\n",
      "2.02465558052063\n",
      "1.9725279808044434\n",
      "1.8152830600738525\n",
      "1.9263596534729004\n",
      "1.864575982093811\n",
      "1.87306809425354\n",
      "1.7375327348709106\n",
      "1.8347750902175903\n",
      "1.810659408569336\n",
      "2.0236470699310303\n",
      "1.9497673511505127\n",
      "1.7865790128707886\n",
      "1.7666958570480347\n",
      "2.0288612842559814\n",
      "1.7430367469787598\n",
      "1.8447867631912231\n",
      "1.946676254272461\n",
      "2.0322680473327637\n",
      "1.9551442861557007\n",
      "1.783348560333252\n",
      "1.9497027397155762\n",
      "1.888240098953247\n",
      "1.9483118057250977\n",
      "2.05204701423645\n",
      "1.8895020484924316\n",
      "1.666178822517395\n",
      "2.112830877304077\n",
      "1.954969048500061\n",
      "1.7851834297180176\n",
      "1.8659199476242065\n",
      "1.9226198196411133\n",
      "1.8913506269454956\n",
      "1.882672905921936\n",
      "1.9430049657821655\n",
      "2.035238742828369\n",
      "2.014575958251953\n",
      "1.9406373500823975\n",
      "1.8115928173065186\n",
      "1.9011976718902588\n",
      "1.804874062538147\n",
      "1.9846910238265991\n",
      "1.7100814580917358\n",
      "1.8495200872421265\n",
      "1.875539779663086\n",
      "1.906010389328003\n",
      "1.855364203453064\n",
      "1.958072304725647\n",
      "1.9310059547424316\n",
      "1.8087217807769775\n",
      "2.0602877140045166\n",
      "2.0504109859466553\n",
      "2.019462823867798\n",
      "1.7958555221557617\n",
      "1.8500921726226807\n",
      "1.9093258380889893\n",
      "1.8425747156143188\n",
      "1.793847918510437\n",
      "1.9542683362960815\n",
      "1.8294563293457031\n",
      "2.0223495960235596\n",
      "1.8837960958480835\n",
      "1.7420717477798462\n",
      "1.836641550064087\n",
      "2.0687456130981445\n",
      "1.9515230655670166\n",
      "1.7768696546554565\n",
      "1.8417491912841797\n",
      "1.889824390411377\n",
      "1.9735175371170044\n",
      "1.8939473628997803\n",
      "1.9079622030258179\n",
      "1.7687550783157349\n",
      "1.7830939292907715\n",
      "1.9059127569198608\n",
      "2.005565881729126\n",
      "1.9469332695007324\n",
      "1.693913459777832\n",
      "1.9709495306015015\n",
      "1.8582706451416016\n",
      "2.0022964477539062\n",
      "1.8747780323028564\n",
      "2.073007345199585\n",
      "1.928421139717102\n",
      "1.9836794137954712\n",
      "1.7066140174865723\n",
      "1.767982006072998\n",
      "1.8971620798110962\n",
      "1.7227694988250732\n",
      "1.6953024864196777\n",
      "2.17052960395813\n",
      "1.7554837465286255\n",
      "1.9501631259918213\n",
      "1.7240219116210938\n",
      "1.8571674823760986\n",
      "1.958742380142212\n",
      "1.95151686668396\n",
      "2.017364978790283\n",
      "1.8140932321548462\n",
      "1.9188557863235474\n",
      "1.8669981956481934\n",
      "1.832949161529541\n",
      "1.7663096189498901\n",
      "2.0416064262390137\n",
      "1.8693346977233887\n",
      "1.8964582681655884\n",
      "1.9197605848312378\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # mini batch creation and getting embeddings\n",
    "    batch_idx = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "    xs = X_train[batch_idx]\n",
    "    ys = Y[batch_idx].view(-1)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(xs)\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "\n",
    "    # backward pass\n",
    "    for param in parameters:\n",
    "        param.grad = None\n",
    "    loss.backward()\n",
    "    print(loss.item())\n",
    "\n",
    "    # update step\n",
    "    lr = 0.05\n",
    "    for param in parameters:\n",
    "        param.data += -lr * param.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
